xvfb-run -a -s "-screen 0 1400x900x24 +extension RANDR" -- bash

CUDA_VISIBLE_DEVICES=3 xvfb-run -a -s "-screen 0 1400x900x24 +extension RANDR" python3 trpo_test.py --nactor 20 --batch-size 20000

tmux kill-window -t 9

sshfs dy2:/home/data/czeng/ ~/dy2

LD_LIBRARY_PATH=$HOME/.mujoco/mjpro150/bin pip3 install --user --upgrade .

CUDA_VISIBLE_DEVICES=3 python3 trpo_test.py --nactor 20

pip3 freeze | grep -v "^-e" | xargs pip3 uninstall -y

from pympler import muppy, summary
all_objects = muppy.get_objects()
len(all_objects)
sum1 = summary.summarize(all_objects)
summary.print_(sum1)

summary.print_(summary.summarize(muppy.get_objects()))

pip3.6 --no-cache-dir install --user --force-reinstall https://github.com/mind/wheels/releases/download/tf1.4-gpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl
tmu

cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_PYTHON3=ON

import cv2;cv2.imshow('ob',obs[1][0]);cv2.waitKey(0);cv2.destroyAllWindows()


img=img_input[0,:,:,0]
import cv2;cv2.imshow('ob',img);cv2.waitKey(0);cv2.destroyAllWindows()

from matplotlib import pyplot as plt;plt.figure(1);plt.imshow(obs[1][0,:,:,0], cmap='gray', interpolation='bicubic');plt.xticks([]), plt.yticks([]);plt.draw()


CUDA_VISIBLE_DEVICES=1 python3 trpo_test.py --nactor 20 --batch-size 10000

python3.6 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())"

cmake -DCMAKE_BUILD_TYPE=Release -DBUILD_PYTHON3=ON \
-DPYTHON_INCLUDE_DIRS=$(python3.6 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())")  \
-DPYTHON_LIBRARIES=$(python3.6 -c "import distutils.sysconfig as sysconfig; import os; print(os.path.join(sysconfig.get_config_var('LIBDIR'), sysconfig.get_config_var('LDLIBRARY')))")

python3 -c "import distutils.sysconfig as sysconfig; import os; print(os.path.join(sysconfig.get_config_var('LIBDIR'), sysconfig.get_config_var('LDLIBRARY')))"

python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())"

java -jar ../pp2check/jplag.jar -l python3 -s . -r 0result -bc 0base -m 30%

registeruser
mail peterzengcc@gmail.com

for d in */ ; do
    mv $d/*/**/*(.D) $d
done

sudo ifconfig wlp2s0 down && sudo ifconfig wlp2s0 up

while true; do
if ! ping -q -w 1 -c 1 `ip r | grep default | cut -d ' ' -f 3` > /dev/null; then
nmcli --wait 20 c up eduroam
echo connecting
else
echo connected
fi;
sleep 2;
done
nvidia-smi --query-gpu="utilization.gpu,memory.free,memory.used" --format=csv -lms 500
nvidia-smi --query-gpu="accounting.mode" --format=csv

nvidia-smi -q -d "MEMORY,UTILIZATION" -lms 500
nvidia-smi --query-accounted-apps="gpu_utilization" --format=csv
CUDA_VISIBLE_DEVICES=2 disprun python3.6 pg_train.py --env move_up_for --rl-method ACKTR --nactor 20 --batch-size 20000 --withimg 1 --nfeat 30 --load-model 0 --lr 0.0001 --vlr 0.003 --load-leaf 1 --train-leaf 0 --npret -1 --ent-k 0.1 --loss PPO  --norm-gae 1 --kl 0.0001 --load-dir models_target --switcher-length 50
python3.6 pg_train.py --env scalemove1d --rl-method ACKTR --nactor 20 --batch-size 4000 --withimg 1 --nfeat 30 --load-model 0 --kl 0.0003 --vlr 0.001
CUDA_VISIBLE_DEVICES=2 disprun python3.6 pg_train.py --env simplehrl1d --rl-method ACKTR --nactor 20 --batch-size 20000 --withimg 1 --nfeat 30 --load-model 0 --vlr 0.003 --load-leaf 1 --train-leaf 0 --npret -1 --ent-k 0.0 --loss PPO  --kl 0.001 --load-dir models_target --switcher-length 20

mux
CUDA_VISIBLE_DEVICES=2 disprun python3.6 pg_train.py --env move1d --rl-method ACKTR --nactor 20 --batch-size 20000 --withimg 1 --nfeat 30 --load-model 0 --vlr 0.003 --load-leaf 1 --train-leaf 0 --npret -1 --ent-k 0.01 --loss PPO  --kl 0.001 --load-dir models_target --switcher-length 20
CUDA_VISIBLE_DEVICES=2 disprun python3.6 pg_train.py --env move1d --rl-method ACKTR --nactor 20 --batch-size 20000 --withimg 1 --nfeat 30 --load-model 0 --vlr 0.003 --load-leaf 1 --train-leaf 0 --npret -1 --ent-k 0.01 --loss PPO  --kl 0.001 --load-dir models_target --switcher-length 20
CUDA_VISIBLE_DEVICES=1 disprun python3.6 pg_train.py --env scalemove1d --rl-method ACKTR --nactor 20 --batch-size 4000 --withimg 1 --nfeat 30 --load-model 0 --kl 0.0003 --vlr 0.001
CUDA_VISIBLE_DEVICES=0 disprun python3.6 pg_train.py --env move0 --rl-method ACKTR --nactor 20 --batch-size 2500 --withimg 1 --nfeat 30 --load-model 0 --kl 0.0003 --vlr 0.001

CUDA_VISIBLE_DEVICES=0 python3.6 pg_train.py --env move4 --rl-method ACKTR --nactor 20 --batch-size 2500 --withimg 0 --nfeat 0 --load-model 0 --kl 0.0001 --vlr 0.001


CUDA_VISIBLE_DEVICES=0,1,2
mux6
CUDA_VISIBLE_DEVICES=1 xvfb-run -a -s "-screen 0 1400x900x24 +extension RANDR" python3.6 pg_train.py --env dynamic2d --rl-method PG --nactor 20 --batch-size 4000 --withimg 1 --nfeat 30 --load-model 0 --lr 0.003 --kl 0.001 --load-leaf 0 --train-leaf 1 --npret 37500 --num-steps 600000000

1mux0
CUDA_VISIBLE_DEVICES=0 disprun python3.6 pg_train.py --env move1d --rl-method ACKTR --nactor 20 --batch-size 20000 --withimg 1 --nfeat 30 --load-model 0 --lr 0.001 --vlr 0.002 --load-leaf 1 --train-leaf 0 --npret -1 --ent-k 0.01 --loss PPO  --kl 0.0002 --load-dir models --switcher-length 25

local :
python3.6 pg_train.py --env move0 --rl-method PG --nactor 20 --batch-size 4000 --withimg 0 --nfeat 0 --load-model 0 --kl 0.0001 --vlr 0.001 --loss PPO_TRAD


record:
CUDA_VISIBLE_DEVICES="" python3.6 pg_train.py --nactor 1 --num-steps 5000 --batch-size 400 --withimg 1 --env simplemove1d --nfeat 30 --load-model 1 --no-train 1 --save-model 0 --render record --load-dir exp_7

LD_PRELOAD="${M2WS}/lib/faketime/libfaketime.so.1" FAKETIME="2020-01-01" bash

CUDA_VISIBLE_DEVICES="" python3.6 ./project2.py --task train_cnn
python3.6 ./project2.py --task train_ae && python3.6 ./project2.py --task evaluate_ae

import matplotlib.pyplot as plt

i +=0

i +=1;plt.figure(0);plt.imshow(x[i,:,:],cmap="gray");plt.figure(1);plt.imshow(recon[i,:,:,0],cmap="gray");plt.figure(2);plt.imshow(np.reshape(features[i,:,:,:],(7,7,1)),cmap="gray")


CUDA_VISIBLE_DEVICES="" python3.6 ./project2.py --task train_ae

i += 1;visualize_ae(i,x,features,recon)

hist = np.histogram(sampled_y_test,bins=47)[0]


