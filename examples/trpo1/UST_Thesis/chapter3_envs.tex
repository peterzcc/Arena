\section{TODO: Target Environments}\label{sec_env}
\subsection{Ant-based environments}
\subsubsection{Summary of Environments}
The source environments and target environments are summarized in table \ref{table_ant_envs}.


\begin{table}[h]

\begin{center}
\begin{tabular}{|c|p{3cm}|p{4cm}|p{4cm}|}
\hline
Task name & Goal & Reward  &  Description \\
\hline\hline
move0 & velocity: $g_0=(1,0)$ &$ v_g+1-c_p-c_c$  & move toward east direction \\
\hline
move1 & velocity: $g_1=(-1,0)$ &$ v_g+1-c_p-c_c$  & move toward west direction \\
\hline
move2 & velocity: $g_2=(0,1)$ &$ v_g+1-c_p-c_c$  & move toward north direction \\
\hline
move3 & velocity: $g_3=(0,-1)$ &$ v_g+1-c_p-c_c$  & move toward south direction \\ 
\hline 
move1d & velocity: $\{g_0,g_1\}$ &$ v_g+1-c_p-c_c$  & each episode has a random sampled goal direction \\ \hline
move2d & velocity: $\{g_0,g_1,g_2,g_3\}$ &$ v_g+1-c_p-c_c$  & there are 4 possible goal directions compared to move1d \\ \hline
dynamic2d & velocity: $\{g_0,g_1,g_2,g_3\}$ &$ v_g+1-c_p-c_c$  & the goal direction is reset with probability 0.01 \\ \hline
reach2d & position: $\{g_0,g_1,g_2,g_3\}$ & I(The agent's distance to the goal position is within 0.5)$-0.01$  & move to a specific location instead of a direction\\ \hline

\hline
\end{tabular}
\end{center}
\caption{Summary of Ant-based environments}
\end{table}\label{table_ant_envs}


\subsubsection{Dynamic2D environment}
\subsubsection{Reach2D environment}
\subsection{TODO: Robot manipulation environments}
