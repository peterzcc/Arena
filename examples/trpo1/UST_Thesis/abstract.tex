%!TEX program = xelatex
%!TEX root = ./thesis.tex
\begin{center}
{\Large \thesistitle}\\
\vspace{20mm}
by \thesisauthor\\
\vspace{15mm}
\departmentname\\
\vspace{10mm}
The Hong Kong University of Science and Technology
\end{center}
\vspace{8mm}
\begin{center}
Abstract

Solving realistic problems automatically without domain-specific engineering has been one of the most fascinating problems in artificial intelligence. Recent advances in deep reinforcement learning methods have achieved significant progress in game problems. However, a scalable, autonomous solution to realistic problems is still missing.

This thesis studies investigate several continuous control environments with multi-modal state space and sparse rewards, which are considered some typical complex realistic problems. Several methods for flat reinforcement learning methods, including Wasserstein trust-region method, exceptional advantage regularization method, and concentric mixture Gaussian policy model has been proposed to to improve the agent's performance on some of the target tasks. An hierarchical reinforcement learning agent model has also been proposed to solve the target tasks without domain-specific knowledge given a pre-defined set of source tasks. 
\end{center}
\par
\noindent


