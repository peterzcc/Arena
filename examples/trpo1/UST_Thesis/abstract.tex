%!TEX program = xelatex
%!TEX root = ./thesis.tex
\begin{center}
{\Large \thesistitle}\\
\vspace{20mm}
by \thesisauthor\\
\vspace{15mm}
\departmentname\\
\vspace{10mm}
The Hong Kong University of Science and Technology
\end{center}
\vspace{8mm}
\begin{center}
Abstract
\end{center}
One of the most important problems in artificial intelligence is learning to solve control problems without human supervision. Recent advances in deep reinforcement learning methods have achieved significant progresses. Researchers have solved a number of problems including a subset of Atari games~\cite{mnih2015human}, the Go game~\cite{silver2016mastering}, and several simple robot control environments~\cite{duan2016benchmarking}.  However, a solution to more complex problems is still missing. Most real-world robot control problems have multi-modal state space, which usually consists of both a low-dimensional motion sensor input and a high-dimensional image sensor input. Apart from that, a smooth and informative reward signal is usually unavailable in these problem, where the agent is only provided a reward signal that is sparse and discrete.

We develop and study a set continuous control problems with multi-modal state space, some of the which also have sparse reward functions. We propose several techniques to improve the performance of flat reinforcement learning methods on the multi-modal state-space problems, including the Wasserstein actor critic trust-region policy optimization method (W-KTR), the exceptional advantage regularization method, and the robust concentric Gaussian mixture policy model. Experiment results show that the proposed methods, especially the exceptional advantage regularization method, lead to considerable improvement on the flat reinforcement learning agent's performance. A hierarchical reinforcement learning method, namely flexible-scheduling hierarchical method, is proposed for the sparse-reward problems. Experiment results show that the flexible-scheduling hierarchical method can solve the proposed multi-modal state space and sparse-reward problems given a set of pre-defined source tasks.

\par
\noindent


