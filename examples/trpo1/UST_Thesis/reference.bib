% This file was created with JabRef 2.10.
% Encoding: GBK
@article{vezhnevets2017feudal,
	title={Feudal networks for hierarchical reinforcement learning},
	author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
	journal={arXiv preprint arXiv:1703.01161},
	year={2017}
}
@article{mankowitz2018unicorn,
	title={Unicorn: Continual Learning with a Universal, Off-policy Agent},
	author={Mankowitz, Daniel J and {\v{Z}}{\'\i}dek, Augustin and Barreto, Andr{\'e} and Horgan, Dan and Hessel, Matteo and Quan, John and Oh, Junhyuk and van Hasselt, Hado and Silver, David and Schaul, Tom},
	journal={arXiv preprint arXiv:1802.08294},
	year={2018}
}
@article{andreas2016modular,
	title={Modular multitask reinforcement learning with policy sketches},
	author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
	journal={arXiv preprint arXiv:1611.01796},
	year={2016}
}
@article{shu2017hierarchical,
	title={Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning},
	author={Shu, Tianmin and Xiong, Caiming and Socher, Richard},
	journal={arXiv preprint arXiv:1712.07294},
	year={2017}
}
@preamble{ "\newcommand{\noopsort}[1]{} "
	# "\newcommand{\printfirst}[2]{#1} "
	# "\newcommand{\singleletter}[1]{#1} "
	# "\newcommand{\switchargs}[2]{#2#1} "
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@misc{chafai , title={Wasserstein distance between two Gaussians}, url={http://djalil.chafai.net/blog/2010/04/30/wasserstein-distance-between-two-gaussians/}, journal={Libres penses dun mathmaticien ordinaire}, author={CHAFA√è , Djalil}}
@book{villani2003topics,
  title={Topics in optimal transportation},
  author={Villani, C{\'e}dric},
  number={58},
  year={2003},
  publisher={American Mathematical Soc.}
}
@article{henderson2017matters,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}
@article{nachum2017trust,
  title={Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1707.01891},
  year={2017}
}
@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}
@misc{openaigym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}
@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-Ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}
@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International Conference on Machine Learning},
  pages={1312--1320},
  year={2015}
}

@inproceedings{vezhnevets2016strategic,
  title={Strategic attentive writer for learning macro-actions},
  author={Vezhnevets, Alexander and Mnih, Volodymyr and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Agapiou, John and others},
  booktitle={Advances in neural information processing systems},
  pages={3486--3494},
  year={2016}
}
@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={1329--1338},
  year={2016}
}
@article{plappert2018multi,
  title={Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  author={Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and others},
  journal={arXiv preprint arXiv:1802.09464},
  year={2018}
}
@article{mankowitz2018unicorn,
  title={Unicorn: Continual Learning with a Universal, Off-policy Agent},
  author={Mankowitz, Daniel J and {\v{Z}}{\'\i}dek, Augustin and Barreto, Andr{\'e} and Horgan, Dan and Hessel, Matteo and Quan, John and Oh, Junhyuk and van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1802.08294},
  year={2018},
  note="\url{https://arxiv.org/pdf/1802.08294}"
}
@article{riedmiller2018learning,
  title={Learning by Playing-Solving Sparse Reward Tasks from Scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Van de Wiele, Tom and Mnih, Volodymyr and Heess, Nicolas and Springenberg, Jost Tobias},
  journal={arXiv preprint arXiv:1802.10567},
  year={2018},
  note="\url{https://arxiv.org/pdf/1802.10567}"
}


@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Crow, Dwight and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5055--5065},
  year={2017},
  note="\url{http://papers.nips.cc/paper/7090-hindsight-experience-replay.pdf}"
}

@article{ghosh2017divide,
  title={Divide-and-Conquer Reinforcement Learning},
  author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.09874},
  year={2017}
}

@inproceedings{zhou2017incorporating,
  title={Incorporating side-channel information into convolutional neural networks for robotic tasks},
  author={Zhou, Yilun and Hauser, Kris},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={2177--2183},
  year={2017},
  organization={IEEE}
}
@article{wu2016training,
  title={Training agent for first-person shooter game with actor-critic curriculum learning},
  author={Wu, Yuxin and Tian, Yuandong},
  year={2016}
}
@article{tobin2017domain,
  title={Domain Randomization and Generative Models for Robotic Grasping},
  author={Tobin, Joshua and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1710.06425},
  year={2017}
}
@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4499--4509},
  year={2017}
}
@inproceedings{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5285--5294},
  year={2017}
}

@article{frans2017meta,
  title={Meta Learning Shared Hierarchies},
  author={Frans, Kevin and Ho, Jonathan and Chen, Xi and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1710.09767},
  year={2017}
}
@article{agarwal2016second,
  title={Second order stochastic optimization in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={arXiv preprint arXiv:1602.03943},
  year={2016}
}
@article{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  journal={arXiv preprint arXiv:1703.04730},
  year={2017}
}
@article{schulman2017proximal,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{montgomery2016reset,
  title={Reset-free guided policy search: efficient deep reinforcement learning with stochastic initial states},
  author={Montgomery, William and Ajay, Anurag and Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01112},
  year={2016}
}
@article{gupta2017learning,
  title={Learning invariant feature spaces to transfer skills with reinforcement learning},
  author={Gupta, Abhishek and Devin, Coline and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1703.02949},
  year={2017}
}
@article{lee2017learning,
  title={Learning Visual Servoing with Deep Features and Fitted Q-Iteration},
  author={Lee, Alex X and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1703.11000},
  year={2017}
}
@article{nair2017combining,
  title={Combining Self-Supervised Learning and Imitation for Vision-Based Rope Manipulation},
  author={Nair, Ashvin and Chen, Dian and Agrawal, Pulkit and Isola, Phillip and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
  journal={arXiv preprint arXiv:1703.02018},
  year={2017}
}
@article{liu2017imitation,
  title={Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation},
  author={Liu, YuXuan and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1707.03374},
  year={2017}
}

@article{machado2017laplacian,
  title={A Laplacian Framework for Option Discovery in Reinforcement Learning},
  author={Machado, Marlos C and Bellemare, Marc G and Bowling, Michael},
  journal={arXiv preprint arXiv:1703.00956},
  year={2017}
}
@article{white2016unifying,
  title={Unifying task specification in reinforcement learning},
  author={White, Martha},
  journal={arXiv preprint arXiv:1609.01995},
  year={2016}
}
@article{vezhnevets2017feudal,
  title={FeUdal Networks for Hierarchical Reinforcement Learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1703.01161},
  year={2017}
}
@book{rlintro_sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}
@article{devin2016learning,
  title={Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer},
  author={Devin, Coline and Gupta, Abhishek and Darrell, Trevor and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1609.07088},
  year={2016}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Research}
}
@article{gu2016q,
  title={Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}
@article{qprop,
  title={Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}
@article{deepVisualForsight,
  title={Deep Visual Foresight for Planning Robot Motion},
  author={Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.00696},
  year={2016}
}
@article{sim2realInverse,
  title={Transfer from Simulation to Real World through Learning Deep Inverse Dynamics Model},
  author={Christiano, Paul and Shah, Zain and Mordatch, Igor and Schneider, Jonas and Blackwell, Trevor and Tobin, Joshua and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1610.03518},
  year={2016}
}
@inproceedings{adaptSim2real,
  title={Adapting deep visuomotor representations with weak pairwise constraints},
  author={Tzeng, Eric and Devin, Coline and Hoffman, Judy and Finn, Chelsea and Abbeel, Pieter and Levine, Sergey and Saenko, Kate and Darrell, Trevor},
  booktitle={Workshop on the Algorithmic Foundations of Robotics (WAFR)},
  year={2016}
}
@article{carlos2016stochastic,
  title={STOCHASTIC NEURAL NETWORKS FOR HIERARCHICAL REINFORCEMENT LEARNING},
  author={Carlos Florensa, Yan Duan, Pieter Abbeel},
  note="\url{https://openreview.net/forum?id=B1oK8aoxe}"
}
@article{iclr2017invariant,
  title={Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning},
  author={Abhishek Gupta, Coline Devin, YuXuan Liu, Pieter Abbeel, Sergey Levine},
  note="\url{https://openreview.net/forum?id=Hyq4yhile}"
}
@article{iclr2017generalize,
  title={Generalizing Skills with Semi-Supervised Reinforcement Learning},
  author={Chelsea Finn, Tianhe Yu, Justin Fu, Pieter Abbeel, Sergey Levine},
  note="\url{https://openreview.net/forum?id=ryHlUtqge}"
}
@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={The Journal of Machine Learning Research},
  volume={12},
  pages={2121--2159},
  year={2011},
  publisher={JMLR. org}
}
@article{devin2016learning,
  title={Learning Modular Neural Network Policies for Multi-Task and Multi-Robot Transfer},
  author={Devin, Coline and Gupta, Abhishek and Darrell, Trevor and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1609.07088},
  year={2016}
}
@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}
@article{ferguson2006proto,
  title={Proto-transfer learning in markov decision processes using spectral methods},
  author={Ferguson, Kimberly and Mahadevan, Sridhar},
  journal={Computer Science Department Faculty Publication Series},
  pages={151},
  year={2006}
}
@inproceedings{andre2002state,
  title={State abstraction for programmable reinforcement learning agents},
  author={Andre, David and Russell, Stuart J},
  booktitle={AAAI/IAAI},
  pages={119--125},
  year={2002}
}
@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey},
  author={Taylor, Matthew E and Stone, Peter},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Jul},
  pages={1633--1685},
  year={2009}
}
@inproceedings{pan2008transfer,
  title={Transfer Learning via Dimensionality Reduction.},
  author={Pan, Sinno Jialin and Kwok, James T and Yang, Qiang},
  booktitle={AAAI},
  volume={8},
  pages={677--682},
  year={2008}
}
@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{andre2002state,
  title={State abstraction for programmable reinforcement learning agents},
  author={Andre, David and Russell, Stuart J},
  booktitle={AAAI/IAAI},
  pages={119--125},
  year={2002}
}
@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={J. Artif. Intell. Res.(JAIR)},
  volume={13},
  pages={227--303},
  year={2000}
}

@inproceedings{hengst2002discovering,
  title={Discovering hierarchy in reinforcement learning with HEXQ},
  author={Hengst, Bernhard},
  booktitle={ICML},
  volume={2},
  pages={243--250},
  year={2002}
}
@article{joshua2016suprise,
  title={SURPRISE-BASED INTRINSIC MOTIVATION FOR DEEP REINFORCEMENT LEARNING},
  author={Joshua Achiam & Shankar Sastry},
  note="\url{http://openreview.net/pdf?id=Bk8aOm9xl}"
}
@article{jacob2016modular,
  title={MODULAR MULTITASK REINFORCEMENT LEARNING WITH POLICY SKETCHES},
  author={Jacob Andreas, Dan Klein, and Sergey Levine},
  note="\url{http://openreview.net/pdf?id=H1kjdOYlx}"
}

@article{buschman2014goal,
  title={Goal-direction and top-down control},
  author={Buschman, Timothy J and Miller, Earl K},
  journal={Phil. Trans. R. Soc. B},
  volume={369},
  number={1655},
  pages={20130471},
  year={2014},
  publisher={The Royal Society},
  note="\url{http://rstb.royalsocietypublishing.org/content/369/1655/20130471.short}"
}
@article{pezzulo2014principles,
  title={The principles of goal-directed decision-making: from neural mechanisms to computation and robotics},
  author={Pezzulo, Giovanni and Verschure, Paul FMJ and Balkenius, Christian and Pennartz, Cyriel MA},
  journal={Phil. Trans. R. Soc. B},
  volume={369},
  number={1655},
  pages={20130470},
  year={2014},
  publisher={The Royal Society},
  note="\url{http://rstb.royalsocietypublishing.org/content/369/1655/20130470.short}"
}
@article{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I and Abbeel, Pieter},
  journal={CoRR, abs/1502.05477},
  year={2015},
  note="\url{http://www.jmlr.org/proceedings/papers/v37/schulman15.pdf}"
}
@article{marblestone2016toward,
  title={Toward an integration of deep learning and neuroscience},
  author={Marblestone, Adam H and Wayne, Greg and Kording, Konrad P},
  journal={Frontiers in Computational Neuroscience},
  volume={10},
  year={2016},
  publisher={Frontiers Media SA}
}
@article{heess2016learning,
  title={Learning and Transfer of Modulated Locomotor Controllers},
  author={Heess, Nicolas and Wayne, Greg and Tassa, Yuval and Lillicrap, Timothy and Riedmiller, Martin and Silver, David},
  journal={arXiv preprint arXiv:1610.05182},
  year={2016},
  note="\url{https://arxiv.org/pdf/1610.05182}"
}
@article{gu2016deep,
  title={Deep Reinforcement Learning for Robotic Manipulation},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.00633},
  year={2016},
  note="\url{https://arxiv.org/pdf/1610.00633.pdf}"
}

@book{murray1994mathematical,
  title={A mathematical introduction to robotic manipulation},
  author={Murray, Richard M and Li, Zexiang and Sastry, S Shankar and Sastry, S Shankara},
  year={1994},
  publisher={CRC press},
  note="\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.671.7040&rep=rep1&type=pdf}"
}
@inproceedings{hart2008intrinsically,
  title={Intrinsically motivated hierarchical manipulation.},
  author={Hart, Stephen and Sen, Shiraj and Grupen, Roderic A},
  booktitle={ICRA},
  pages={3814--3819},
  year={2008},
  note="\url{https://pdfs.semanticscholar.org/b51c/50a49f7a4bfb9177a1a7b23720d35c816013.pdf}"
}
@article{sentis2005synthesis,
  title={Synthesis of whole-body behaviors through hierarchical control of behavioral primitives},
  author={Sentis, Luis and Khatib, Oussama},
  journal={International Journal of Humanoid Robotics},
  volume={2},
  number={04},
  pages={505--518},
  year={2005},
  publisher={World Scientific},
  note="\url{http://www.robotics.stanford.edu/~lsentis/files/ijhr-05-old.pdf}"
}
@article{kalakrishnan2011learning,
  title={Learning, planning, and control for quadruped locomotion over challenging terrain},
  author={Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
  journal={The International Journal of Robotics Research},
  volume={30},
  number={2},
  pages={236--258},
  year={2011},
  publisher={SAGE Publications},
  note = "\url{https://www.cse.unr.edu/robotics/bekris/cs773_s12/sites/cse.unr.edu.robotics.bekris.cs773_s12/files/paper_09.pdf}"
}
@article{moradi2012automatic,
  title={Automatic skill acquisition in reinforcement learning using graph centrality measures},
  author={Moradi, Parham and Shiri, Mohammad Ebrahim and Rad, Ali Ajdari and Khadivi, Alireza and Hasler, Martin},
  journal={Intelligent Data Analysis},
  volume={16},
  number={1},
  pages={113--135},
  year={2012},
  publisher={IOS Press}
}
@inproceedings{goel2003subgoal,
  title={Subgoal Discovery for Hierarchical Reinforcement Learning Using Learned Policies.},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}
@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}
@article{rusu2016progressive,
  title={Progressive Neural Networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}
@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik R and Saeedi, Ardavan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1604.06057},
  year={2016}
}
@article{botvinick2012hierarchical,
  title={Hierarchical reinforcement learning and decision making},
  author={Botvinick, Matthew Michael},
  journal={Current opinion in neurobiology},
  volume={22},
  number={6},
  pages={956--962},
  year={2012},
  publisher={Elsevier}
}
@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete Event Dynamic Systems},
  volume={13},
  number={4},
  pages={341--379},
  year={2003},
  publisher={Springer}
}
@article{zrihemvisualizing,
  title={Visualizing Dynamics: from t-SNE to SEMI-MDPs},
  author={Zrihem, Nir Ben and Zahavy, COM Tom and Mannor, Shie}
}

@inproceedings{whitman2010control,
  title={Control of instantaneously coupled systems applied to humanoid walking},
  author={Whitman, Eric C and Atkeson, Christopher G},
  booktitle={2010 10th IEEE-RAS International Conference on Humanoid Robots},
  pages={210--217},
  year={2010},
  organization={IEEE}
}
@inproceedings{soni2006reinforcement,
  title={Reinforcement learning of hierarchical skills on the Sony Aibo robot},
  author={Soni, Vishal and Singh, Satinder},
  booktitle={Proceedings of the Fifth International Conference on Development and Learning},
  year={2006}
}
@article{morimoto2001acquisition,
  title={Acquisition of stand-up behavior by a real robot using hierarchical reinforcement learning},
  author={Morimoto, Jun and Doya, Kenji},
  journal={Robotics and Autonomous Systems},
  volume={36},
  number={1},
  pages={37--51},
  year={2001},
  publisher={Elsevier}
}
@article{konidaris2011robot,
  title={Robot learning from demonstration by constructing skill trees},
  author={Konidaris, George and Kuindersma, Scott and Grupen, Roderic and Barto, Andrew},
  journal={The International Journal of Robotics Research},
  pages={0278364911428653},
  year={2011},
  publisher={SAGE Publications}
}
@inproceedings{konidaris2011autonomous,
  title={Autonomous Skill Acquisition on a Mobile Manipulator.},
  author={Konidaris, George and Kuindersma, Scott and Grupen, Roderic A and Barto, Andrew G},
  booktitle={AAAI},
  year={2011}
}
@inproceedings{kirchner1997q,
  title={Q-learning of complex behaviours on a six-legged walking machine},
  author={Kirchner, Frank},
  booktitle={Advanced Mobile Robots, 1997. Proceedings., Second EUROMICRO workshop on},
  pages={51--58},
  year={1997},
  organization={IEEE}
}
@inproceedings{kalmar1997modular,
  title={Modular reinforcement learning: An application to a real robot task},
  author={Kalm{\'a}r, Zsolt and Szepesv{\'a}ri, Csaba and Lorincz, Andr{\'a}s},
  booktitle={European Workshop on Learning Robots},
  pages={29--45},
  year={1997},
  organization={Springer}
}
@article{huber1997feedback,
  title={A feedback control structure for on-line learning tasks},
  author={Huber, Manfred and Grupen, Roderic A},
  journal={Robotics and autonomous systems},
  volume={22},
  number={3},
  pages={303--315},
  year={1997},
  publisher={Elsevier}
}
@article{hart2011learning,
  title={Learning generalizable control programs},
  author={Hart, Stephen and Grupen, Roderic},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={3},
  number={3},
  pages={216--231},
  year={2011},
  publisher={IEEE}
}
@inproceedings{fidelman2004learning,
  title={Learning ball acquisition on a physical robot},
  author={Fidelman, Peggy and Stone, Peter},
  booktitle={2004 International Symposium on Robotics and Automation (ISRA)},
  pages={6},
  year={2004}
}
@article{donnart1996learning,
  title={Learning reactive and planning rules in a motivationally autonomous animat},
  author={Donnart, J-Y and Meyer, J-A},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume={26},
  number={3},
  pages={381--395},
  year={1996},
  publisher={IEEE}
}
@inproceedings{daniel2012learning,
  title={Learning concurrent motor skills in versatile solution spaces},
  author={Daniel, Christian and Neumann, Gerhard and Peters, Jan},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3591--3597},
  year={2012},
  organization={IEEE}
}
@incollection{asada1996purposive,
  title={Purposive behavior acquisition for a real robot by vision-based reinforcement learning},
  author={Asada, Minoru and Noda, Shoichi and Tawaratsumida, Sukoya and Hosoda, Koh},
  booktitle={Recent Advances in Robot Learning},
  pages={163--187},
  year={1996},
  publisher={Springer}
}
@article{mnih2016strategic,
  title={Strategic Attentive Writer for Learning Macro-Actions},
  author={Mnih, Volodymyr and Agapiou, John and Osindero, Simon and Graves, Alex and Vinyals, Oriol and Kavukcuoglu, Koray and others},
  journal={arXiv preprint arXiv:1606.04695},
  year={2016}
}

@article{schaul2015prioritized,
  title={Prioritized Experience Replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}
@inproceedings{li2014scaling,
  title={Scaling distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
  booktitle={11th USENIX Symposium on Operating Systems Design and Implementation (OSDI 14)},
  pages={583--598},
  year={2014}
}
@article{mnih2016asynchronous,
  title={Asynchronous Methods for Deep Reinforcement Learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1602.01783},
  year={2016}
}
@inproceedings{zhang2015deep,
  title={Deep learning with elastic averaging SGD},
  author={Zhang, Sixin and Choromanska, Anna E and LeCun, Yann},
  booktitle={Advances in Neural Information Processing Systems},
  pages={685--693},
  year={2015}
}

@article{zeiler2012adadelta,
  title={ADADELTA: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@article{van2015deep,
  title={Deep reinforcement learning with double Q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  journal={arXiv preprint arXiv:1509.06461},
  year={2015}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}
@article{nair2015massively,
  title={Massively Parallel Methods for Deep Reinforcement Learning},
  author={Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and others},
  journal={arXiv preprint arXiv:1507.04296},
  year={2015}
}
@article{hausknecht2015deep,
  title={Deep Recurrent Q-Learning for Partially Observable MDPs},
  author={Hausknecht, Matthew and Stone, Peter},
  journal={arXiv preprint arXiv:1507.06527},
  year={2015}
}
@article{spragueparameter,
  title={Parameter Selection for the Deep Q-Learning Algorithm},
  author={Sprague, Nathan}
}
@article{levine2015end,
  title={End-to-End Training of Deep Visuomotor Policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1504.00702},
  year={2015}
}
@inproceedings{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3338--3346},
  year={2014}
}
@article{zambranocontinuous,
  title={Continuous-time on-policy neural reinforcement learning of working memory tasks},
  author={Zambrano, Davide and Roelfsema, Pieter R and Bohte, Sander M}
}
@article{cully2015robots,
  title={Robots that can adapt like animals},
  author={Cully, Antoine and Clune, Jeff and Tarapore, Danesh and Mouret, Jean-Baptiste},
  journal={Nature},
  volume={521},
  number={7553},
  pages={503--507},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{bellemare2012arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={arXiv preprint arXiv:1207.4708},
  year={2012}
}
@article{goodrichmitigating,
  title={Mitigating Catastrophic Forgetting in Temporal Difference Learning with Function Approximation},
  author={Goodrich, Benjamin and Arel, Itamar}
}

@inproceedings{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3338--3346},
  year={2014}
}
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}
@article{lai2015giraffe,
  title={Giraffe: Using Deep Reinforcement Learning to Play Chess},
  author={Lai, Matthew},
  journal={arXiv preprint arXiv:1509.01549},
  year={2015}
}
@article{parisotto2015actor,
  title={Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  pages={0278364913495721},
  year={2013},
  publisher={SAGE Publications}
}
