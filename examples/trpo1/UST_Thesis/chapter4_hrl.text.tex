%!TEX program = xelatex
%!TEX root = ./thesis.tex

\section{Hierarchical reinforcement learning methods for multi-modality and sparse environments}
This section will discuss the experiments on the proposed hierarchical reinforcement learning models.

In our experiment settings, we choose the set $\{move0, move1, \dots, move7 \}$ as source tasks. We select "dynamicg4" as a representative target task for multi-modality environments and "reachcont" as a representative target task for multi-modality sparse environments.

The problem of hierarchical reinforcement learning is divided into two parts: learning robust actuator policies and learning the decider policies.